# AI Gateway - BazChat OSS AI Microservice

Microservi√ßo de IA para BazChat usando **apenas modelos open-source**.

## üéØ Objetivos

- **100% Open Source**: Nenhum modelo propriet√°rio ou API externa
- **On-Premise**: Roda localmente ou em servidor pr√≥prio
- **Privacy-First**: Dados n√£o saem da infraestrutura
- **Multilingual**: Suporte a tradu√ß√£o, STT, TTS em v√°rios idiomas

## ü§ñ Modelos Utilizados

| Funcionalidade | Modelo OSS | Framework |
|----------------|------------|-----------|
| LLM (Chat) | Llama 3 8B Instruct | vLLM |
| Translation | NLLB-200 (600M) | HuggingFace |
| STT | Whisper Large V3 | faster-whisper |
| TTS | XTTS v2 | Coqui-TTS |
| Embeddings | all-MiniLM-L6-v2 | sentence-transformers |

## üöÄ Endpoints

### `/ai/translate` - Tradu√ß√£o
```bash
POST /ai/translate
{
  "text": "Hello world",
  "sourceLang": "en",
  "targetLang": "pt"
}
```

### `/ai/stt` - Speech-to-Text
```bash
POST /ai/stt
Content-Type: multipart/form-data
file: audio.wav
```

### `/ai/tts` - Text-to-Speech
```bash
POST /ai/tts
{
  "text": "Ol√°, como vai?",
  "language": "pt",
  "speed": 1.0
}
```

### `/ai/complete` - Chat Completion
```bash
POST /ai/complete
{
  "messages": [
    { "role": "user", "content": "Como funciona blockchain?" }
  ],
  "temperature": 0.7,
  "max_tokens": 512
}
```

### `/ai/embed` - Embeddings
```bash
POST /ai/embed
{
  "texts": ["Texto 1", "Texto 2"]
}
```

### `/ai/suggest-reply` - Sugest√µes de Resposta
```bash
POST /ai/suggest-reply
{
  "conversationHistory": [
    "Ol√°!",
    "Oi, como vai?",
    "Tudo bem, e voc√™?"
  ]
}
```

## üõ†Ô∏è Modo MOCK

Por padr√£o, o AI Gateway roda em **MOCK MODE** (sem modelos reais).

Para ativar modelos reais:
1. Deploy os modelos usando vLLM, faster-whisper, etc.
2. Configure as URLs no `.env`
3. Defina `AI_MOCK_MODE=false`

## üì¶ Instala√ß√£o

```bash
cd apps/ai-gateway
pnpm install
pnpm dev
```

## üîß Configura√ß√£o

Edite `.env`:
```bash
PORT=3002
AI_MOCK_MODE=false  # Desabilita MOCK

# URLs dos modelos deployados
VLLM_URL=http://seu-servidor:8000
WHISPER_URL=http://seu-servidor:8001
NLLB_URL=http://seu-servidor:8002
TTS_URL=http://seu-servidor:8003
```

## üê≥ Deploy com Docker

Exemplo de `docker-compose.yml` para deploy dos modelos:

```yaml
version: '3.8'
services:
  vllm:
    image: vllm/vllm-openai:latest
    command: --model meta-llama/Meta-Llama-3-8B-Instruct
    ports:
      - "8000:8000"
    volumes:
      - ./models:/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  whisper:
    image: onerahmet/openai-whisper-asr-webservice:latest
    ports:
      - "8001:9000"
    environment:
      - ASR_MODEL=large-v3
      - ASR_ENGINE=faster_whisper

  # Adicione NLLB e TTS conforme necess√°rio
```

## üìù Notas de Desenvolvimento

- Em MOCK mode, os endpoints retornam placeholders
- Use MOCK mode para desenvolvimento sem GPU
- Para produ√ß√£o, deploy os modelos reais
- Considere usar quantiza√ß√£o (4-bit) para reduzir VRAM
